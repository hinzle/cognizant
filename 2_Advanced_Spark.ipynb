{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P4q_CGf68MS9",
        "OY_vRQlaFtDC",
        "zYBOrt_rGjbQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hinzle/cognizant/blob/main/2_Advanced_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLQhejTr0nXl"
      },
      "source": [
        "# Dataframe basics for PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vnDcDUZ51VG"
      },
      "source": [
        "**Colab only code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kkydKPa5viT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5245c461-a01e-4394-df09-bbfe45881eab"
      },
      "source": [
        "!pip install pyspark --quiet\n",
        "!pip install -U -q PyDrive --quiet \n",
        "!apt install openjdk-8-jdk-headless &> /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 43 kB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 46.9 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkZl8pkJ6gr_"
      },
      "source": [
        "**Setup Spark Session**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8F_0FIE58HT"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HtyLV7G5DM9"
      },
      "source": [
        "Let's start with a subset of the Titanic data on Kaggle and load it into a pandas dataframe, then convert it into a Spark dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuQnNr-pwwKp"
      },
      "source": [
        "data1 = {'PassengerId': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n",
        "         'Name': {0: 'Owen', 1: 'Florence', 2: 'Laina', 3: 'Lily', 4: 'William'},\n",
        "         'Sex': {0: 'male', 1: 'female', 2: 'female', 3: 'female', 4: 'male'},\n",
        "         'Survived': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0}}\n",
        "\n",
        "data2 = {'PassengerId': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n",
        "         'Age': {0: 22, 1: 38, 2: 26, 3: 35, 4: 35},\n",
        "         'Fare': {0: 7.3, 1: 71.3, 2: 7.9, 3: 53.1, 4: 8.0},\n",
        "         'Pclass': {0: 3, 1: 1, 2: 3, 3: 1, 4: 3}}\n",
        "\n",
        "df1_pd = pd.DataFrame(data1, columns=data1.keys())\n",
        "df2_pd = pd.DataFrame(data2, columns=data2.keys())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqXcGg4v6500"
      },
      "source": [
        "Let's look at our Panda's dataframe: df1_pd contents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brzv7Mg06rP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2bfeeb74-0270-46cf-e7e8-7f814cdb337c"
      },
      "source": [
        "df1_pd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId      Name     Sex  Survived\n",
              "0            1      Owen    male         0\n",
              "1            2  Florence  female         1\n",
              "2            3     Laina  female         1\n",
              "3            4      Lily  female         1\n",
              "4            5   William    male         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a12c5a2-f05c-4996-bd50-02928a421cdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Owen</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Florence</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Lily</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>William</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a12c5a2-f05c-4996-bd50-02928a421cdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a12c5a2-f05c-4996-bd50-02928a421cdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a12c5a2-f05c-4996-bd50-02928a421cdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl8HxvQT7Dba"
      },
      "source": [
        "Let's look at the other Panda's dataframe "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HfCt2747HhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a6cd2603-c6ad-4a02-a969-d20c8e4d4d14"
      },
      "source": [
        "df2_pd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Age  Fare  Pclass\n",
              "0            1   22   7.3       3\n",
              "1            2   38  71.3       1\n",
              "2            3   26   7.9       3\n",
              "3            4   35  53.1       1\n",
              "4            5   35   8.0       3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8bcfbdb-c9cc-4851-b2de-5ffd2195f785\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Pclass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>71.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "      <td>7.9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>53.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>35</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8bcfbdb-c9cc-4851-b2de-5ffd2195f785')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8bcfbdb-c9cc-4851-b2de-5ffd2195f785 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8bcfbdb-c9cc-4851-b2de-5ffd2195f785');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkuD5cjv7M44"
      },
      "source": [
        "**We now convert the Panda's dataframe to a Spark dataframe and display its contents**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jLRySjk7S_g",
        "outputId": "ba79ff00-dea6-4800-b126-529e275c0aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1 = spark.createDataFrame(df1_pd)\n",
        "df2 = spark.createDataFrame(df2_pd)\n",
        "df1.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------+\n",
            "|PassengerId|    Name|   Sex|Survived|\n",
            "+-----------+--------+------+--------+\n",
            "|          1|    Owen|  male|       0|\n",
            "|          2|Florence|female|       1|\n",
            "|          3|   Laina|female|       1|\n",
            "|          4|    Lily|female|       1|\n",
            "|          5| William|  male|       0|\n",
            "+-----------+--------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW9rGm_b7hQE"
      },
      "source": [
        "Let's see the schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lApzWjk7kFv",
        "outputId": "7ada27f0-a739-4348-a991-1e92ef6d8bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.printSchema()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Survived: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4q_CGf68MS9"
      },
      "source": [
        "# Basic dataframe transformations\n",
        "\n",
        "![alt text](https://changhsinlee.com/figure/source/2018-03-04-pyspark-dataframe-basics/dataframe-verbs.png)\n",
        "\n",
        "**Select**\n",
        "\n",
        "Takes either a list of column names or an unpacked list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oSJzoi8L6z",
        "outputId": "8e04c0b6-82af-4ed0-d5b0-b7914438aa42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cols1 = ['PassengerId', 'Name']\n",
        "df1.select(cols1).show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+\n",
            "|PassengerId|    Name|\n",
            "+-----------+--------+\n",
            "|          1|    Owen|\n",
            "|          2|Florence|\n",
            "|          3|   Laina|\n",
            "|          4|    Lily|\n",
            "|          5| William|\n",
            "+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljAgPea5AcTm"
      },
      "source": [
        "**Filter**\n",
        "\n",
        "Filter with column expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ws-_VGkAhAO",
        "outputId": "5822adbc-ff0b-4710-db56-350860baef9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.filter(df1.Sex == 'female').show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------+\n",
            "|PassengerId|    Name|   Sex|Survived|\n",
            "+-----------+--------+------+--------+\n",
            "|          2|Florence|female|       1|\n",
            "|          3|   Laina|female|       1|\n",
            "|          4|    Lily|female|       1|\n",
            "+-----------+--------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS955As_ArwQ"
      },
      "source": [
        "Filter with SQL expression. Note the double and single quotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_H2IXLIAsnu",
        "outputId": "81fcfb62-c0b0-4b0d-be94-6b31d61bcd1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.filter(\"Sex='male'\").show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+----+--------+\n",
            "|PassengerId|   Name| Sex|Survived|\n",
            "+-----------+-------+----+--------+\n",
            "|          1|   Owen|male|       0|\n",
            "|          5|William|male|       0|\n",
            "+-----------+-------+----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFnHt7z_A4oT"
      },
      "source": [
        "**Mutate, or creating new columns**\n",
        "\n",
        "Creating new columns in Spark uses `.withColumn()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBYDes7fA8n5",
        "outputId": "4854fcf8-fd4e-4063-8328-7c19d63bb3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2.withColumn('AgeTimesFare', df2.Age*df2.Fare).show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+----+------+------------+\n",
            "|PassengerId|Age|Fare|Pclass|AgeTimesFare|\n",
            "+-----------+---+----+------+------------+\n",
            "|          1| 22| 7.3|     3|       160.6|\n",
            "|          2| 38|71.3|     1|      2709.4|\n",
            "|          3| 26| 7.9|     3|       205.4|\n",
            "|          4| 35|53.1|     1|      1858.5|\n",
            "|          5| 35| 8.0|     3|       280.0|\n",
            "+-----------+---+----+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxcL0FWFBM55"
      },
      "source": [
        "**Summarize and group by**\n",
        "\n",
        "To summarize or aggregate a dataframe, first you need to convert the dataframe to a *GroupedData* object with `groupby()`, then call aggregate transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2tpbol1BZqr",
        "outputId": "432b5dc2-7c3d-465f-e23c-1f8e13e1be04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gdf2 = df2.groupby('Pclass')\n",
        "gdf2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.group.GroupedData at 0x7f87d621bc50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_6G9DVfBe59"
      },
      "source": [
        "Note: We take the average of more than one column by passing an unpacked list of column names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHHG5K9fBwnN",
        "outputId": "6968f887-b478-41e9-d638-a8b0f3c1c5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "avg_cols = ['Age', 'Fare']\n",
        "gdf2.avg(*avg_cols).show() #Note the *, this is unpacking the list!"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+-----------------+\n",
            "|Pclass|          avg(Age)|        avg(Fare)|\n",
            "+------+------------------+-----------------+\n",
            "|     1|              36.5|             62.2|\n",
            "|     3|27.666666666666668|7.733333333333333|\n",
            "+------+------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLPXYIZlCGMf"
      },
      "source": [
        "Note: To call multiple aggregation functions at once, pass a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPT9jFPCOPg",
        "outputId": "9439538d-afc2-4dc6-c9f5-8bd7ed85575e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gdf2.agg({'*': 'count', 'Age': 'avg', 'Fare':'sum'}).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------------------+---------+\n",
            "|Pclass|count(1)|          avg(Age)|sum(Fare)|\n",
            "+------+--------+------------------+---------+\n",
            "|     1|       2|              36.5|    124.4|\n",
            "|     3|       3|27.666666666666668|     23.2|\n",
            "+------+--------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaGTuKbeD5uw"
      },
      "source": [
        "These column names look ugly (at least to me) let's make them read nicely using `toDF()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AtfaeMYD_Y7",
        "outputId": "ed3cc316-aec1-440a-a559-df0e96e91182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(\n",
        "  gdf2.agg({'*': 'count', 'Age': 'avg', 'Fare':'sum'})\n",
        "    .toDF('Pclass', 'counts', 'average_age', 'total_fare')\n",
        "    .show()\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+------------------+----------+\n",
            "|Pclass|counts|       average_age|total_fare|\n",
            "+------+------+------------------+----------+\n",
            "|     1|     2|              36.5|     124.4|\n",
            "|     3|     3|27.666666666666668|      23.2|\n",
            "+------+------+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZwRHY_wEWxO"
      },
      "source": [
        "**Arrange (sort)**\n",
        "\n",
        "Use the `.sort()` method to sort the dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97Ezb7V1Ec5j",
        "outputId": "b476bc2e-7c6a-48c2-dbd5-91c21d73e9c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2.sort('Fare', ascending=False).show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+----+------+\n",
            "|PassengerId|Age|Fare|Pclass|\n",
            "+-----------+---+----+------+\n",
            "|          2| 38|71.3|     1|\n",
            "|          4| 35|53.1|     1|\n",
            "|          5| 35| 8.0|     3|\n",
            "|          3| 26| 7.9|     3|\n",
            "|          1| 22| 7.3|     3|\n",
            "+-----------+---+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-KuUvLbEj2g"
      },
      "source": [
        "**Joins and unions**\n",
        "\n",
        "There are two ways to combine dataframes --- joins and unions. The idea here is the same as joining and unioning tables in SQL.\n",
        "\n",
        "**Joins**\n",
        "\n",
        "Let's Join the two titanic dataframes by the column *PassengerId*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbcviaZ8ExL2",
        "outputId": "a0c26717-5c4c-47b7-8017-438d2b050d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.join(df2, ['PassengerId']).show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------+---+----+------+\n",
            "|PassengerId|    Name|   Sex|Survived|Age|Fare|Pclass|\n",
            "+-----------+--------+------+--------+---+----+------+\n",
            "|          1|    Owen|  male|       0| 22| 7.3|     3|\n",
            "|          2|Florence|female|       1| 38|71.3|     1|\n",
            "|          3|   Laina|female|       1| 26| 7.9|     3|\n",
            "|          4|    Lily|female|       1| 35|53.1|     1|\n",
            "|          5| William|  male|       0| 35| 8.0|     3|\n",
            "+-----------+--------+------+--------+---+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IWTD5RFE5rj"
      },
      "source": [
        "**Nonequi joins**\n",
        "\n",
        "Here is an example of nonequi join. They can be very slow due to skewed data, but this is one operation that Spark can do while Hive can not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_G-fXxRFObx",
        "outputId": "205f3d6c-974f-42b5-edb3-52c151eccc78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.join(df2, df1.PassengerId <= df2.PassengerId).show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------+-----------+---+----+------+\n",
            "|PassengerId|    Name|   Sex|Survived|PassengerId|Age|Fare|Pclass|\n",
            "+-----------+--------+------+--------+-----------+---+----+------+\n",
            "|          1|    Owen|  male|       0|          1| 22| 7.3|     3|\n",
            "|          1|    Owen|  male|       0|          2| 38|71.3|     1|\n",
            "|          2|Florence|female|       1|          2| 38|71.3|     1|\n",
            "|          1|    Owen|  male|       0|          3| 26| 7.9|     3|\n",
            "|          1|    Owen|  male|       0|          4| 35|53.1|     1|\n",
            "|          1|    Owen|  male|       0|          5| 35| 8.0|     3|\n",
            "|          2|Florence|female|       1|          3| 26| 7.9|     3|\n",
            "|          2|Florence|female|       1|          4| 35|53.1|     1|\n",
            "|          2|Florence|female|       1|          5| 35| 8.0|     3|\n",
            "|          3|   Laina|female|       1|          3| 26| 7.9|     3|\n",
            "|          3|   Laina|female|       1|          4| 35|53.1|     1|\n",
            "|          3|   Laina|female|       1|          5| 35| 8.0|     3|\n",
            "|          4|    Lily|female|       1|          4| 35|53.1|     1|\n",
            "|          4|    Lily|female|       1|          5| 35| 8.0|     3|\n",
            "|          5| William|  male|       0|          5| 35| 8.0|     3|\n",
            "+-----------+--------+------+--------+-----------+---+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RtUj9maFYKl"
      },
      "source": [
        "**Unions**\n",
        "\n",
        "`Union()` returns a dataframe from the union of two dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q51JdORUFggb",
        "outputId": "4bc4a6fa-1623-4fc2-fcff-d5e47b11b880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.union(df1).show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------+\n",
            "|PassengerId|    Name|   Sex|Survived|\n",
            "+-----------+--------+------+--------+\n",
            "|          1|    Owen|  male|       0|\n",
            "|          2|Florence|female|       1|\n",
            "|          3|   Laina|female|       1|\n",
            "|          4|    Lily|female|       1|\n",
            "|          5| William|  male|       0|\n",
            "|          1|    Owen|  male|       0|\n",
            "|          2|Florence|female|       1|\n",
            "|          3|   Laina|female|       1|\n",
            "|          4|    Lily|female|       1|\n",
            "|          5| William|  male|       0|\n",
            "+-----------+--------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY_vRQlaFtDC"
      },
      "source": [
        "# Going deeper\n",
        "\n",
        "**Explain(), transformations, and actions**\n",
        "\n",
        "When you create a dataframe in PySpark, unlike Python objects, dataframes are lazy evaluated. What it means is that most operations are *transformations* that modify the execution plan on how Spark should handle the data, but the plan is not executed until we call an *action*.\n",
        "\n",
        "For example, if I want to `join` df1 and df2 on the key *PassengerId* as before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNt7UUhRGCv_",
        "outputId": "ad1937ea-4c3e-4209-b714-4716ac455d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.explain()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) Scan ExistingRDD[PassengerId#0L,Name#1,Sex#2,Survived#3L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKVGmvX2GDwY",
        "outputId": "d41c4c63-0823-4fdd-c046-6e6b86635ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2.explain()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) Scan ExistingRDD[PassengerId#8L,Age#9L,Fare#10,Pclass#11L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80eIdrqRGG-P",
        "outputId": "1865dee9-1a1c-4a39-9c2b-25954ef5247d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dfj1 = df1.join(df2, ['PassengerId'])\n",
        "dfj1.explain()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [PassengerId#0L, Name#1, Sex#2, Survived#3L, Age#9L, Fare#10, Pclass#11L]\n",
            "   +- SortMergeJoin [PassengerId#0L], [PassengerId#8L], Inner\n",
            "      :- Sort [PassengerId#0L ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(PassengerId#0L, 200), ENSURE_REQUIREMENTS, [id=#417]\n",
            "      :     +- Filter isnotnull(PassengerId#0L)\n",
            "      :        +- Scan ExistingRDD[PassengerId#0L,Name#1,Sex#2,Survived#3L]\n",
            "      +- Sort [PassengerId#8L ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(PassengerId#8L, 200), ENSURE_REQUIREMENTS, [id=#418]\n",
            "            +- Filter isnotnull(PassengerId#8L)\n",
            "               +- Scan ExistingRDD[PassengerId#8L,Age#9L,Fare#10,Pclass#11L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4IVNATKGTHG"
      },
      "source": [
        "In this case, `join()` is a transformation that laid out a plan for Spark to join the two dataframes, but it wasn't executed unless you call an action, such as `.count()`, that has to go through the actual data defined by df1 and df2 in order to return a Python object (integer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IosGaMNLGSx0",
        "outputId": "ce1a27a4-aa53-4526-bb59-483de467d89d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dfj1.count()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYBOrt_rGjbQ"
      },
      "source": [
        "# Data persistence: cache() and checkpoint()\n",
        "\n",
        "**caching**\n",
        "\n",
        "Proper caching is the key to high performance Spark. \n",
        "\n",
        "\n",
        "A rule of thumb is that: **Cache a dataframe when it is used multiple times in the script.**\n",
        "\n",
        "Keep in mind that it is only cached after the *first action*. If for whatever reason you want to make sure the data is cached before you save the dataframe, then you have to call an action like `.count()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCYBr09SG01A",
        "outputId": "1e2b414c-aaa9-4035-a49e-6c95f361d3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.cache()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[PassengerId: bigint, Name: string, Sex: string, Survived: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvT7-NFQHAqc"
      },
      "source": [
        "This also works as .cache() is an inplace method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnh6BgrYHCGD"
      },
      "source": [
        "df1 = df1.cache()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCIEhVkDHFCV"
      },
      "source": [
        "To check if a dataframe is cached, check the storageLevel property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7A_fWrpHO1K",
        "outputId": "228dea1c-7c84-4f67-8991-59cc6ad6b782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.storageLevel"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StorageLevel(True, True, False, True, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r09Zv5jaHPvi"
      },
      "source": [
        "To **un-cache** a dataframe, use `unpersist()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Cgex_6HUo0",
        "outputId": "8f47c97e-8a41-48d5-cc92-9ccde2a2dfde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.unpersist()\n",
        "df1.storageLevel\n",
        "# [df2, df3, df4, df1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StorageLevel(False, False, False, False, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2VuXvv3HvKc"
      },
      "source": [
        "**Checkpointing**\n",
        "\n",
        "`checkpoint()` truncates the execution plan and saves the checkpointed dataframe to a temporary location on the disk.\n",
        "\n",
        "It is recommended to do caching before checkpointing so Spark doesn't have to read in the dataframe from disk after it's checkpointed.\n",
        "\n",
        "To use `checkpoint()`, you need to specify the temporary file location to save the datafame to by accessing the sparkContext object from SparkSession."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek1XKpb6H-q1"
      },
      "source": [
        "sc = spark.sparkContext\n",
        "sc.setCheckpointDir(\"/checkpointdir\") # save to ./checkpointdir"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc-AO4tfIGqN"
      },
      "source": [
        "For example, let's join df1 to itself 3 times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQfLm-d5ILbV",
        "outputId": "bef507f9-3e21-4117-b828-e1d4a3cecd61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = df1.join(df1, ['PassengerId'])\n",
        "df.join(df1, ['PassengerId']).explain()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [PassengerId#0L, Name#1, Sex#2, Survived#3L, Name#396, Sex#397, Survived#398L, Name#407, Sex#408, Survived#409L]\n",
            "   +- SortMergeJoin [PassengerId#0L], [PassengerId#406L], Inner\n",
            "      :- Project [PassengerId#0L, Name#1, Sex#2, Survived#3L, Name#396, Sex#397, Survived#398L]\n",
            "      :  +- SortMergeJoin [PassengerId#0L], [PassengerId#395L], Inner\n",
            "      :     :- Sort [PassengerId#0L ASC NULLS FIRST], false, 0\n",
            "      :     :  +- Exchange hashpartitioning(PassengerId#0L, 200), ENSURE_REQUIREMENTS, [id=#663]\n",
            "      :     :     +- Filter isnotnull(PassengerId#0L)\n",
            "      :     :        +- Scan ExistingRDD[PassengerId#0L,Name#1,Sex#2,Survived#3L]\n",
            "      :     +- Sort [PassengerId#395L ASC NULLS FIRST], false, 0\n",
            "      :        +- Exchange hashpartitioning(PassengerId#395L, 200), ENSURE_REQUIREMENTS, [id=#664]\n",
            "      :           +- Filter isnotnull(PassengerId#395L)\n",
            "      :              +- Scan ExistingRDD[PassengerId#395L,Name#396,Sex#397,Survived#398L]\n",
            "      +- Sort [PassengerId#406L ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(PassengerId#406L, 200), ENSURE_REQUIREMENTS, [id=#671]\n",
            "            +- Filter isnotnull(PassengerId#406L)\n",
            "               +- Scan ExistingRDD[PassengerId#406L,Name#407,Sex#408,Survived#409L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Ns03yWIPku"
      },
      "source": [
        "Let's `checkpoint()` after the first `join` to truncate the plan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMWt210yIX7o",
        "outputId": "c8f0ce4a-7239-467a-93dd-ee754c65bdbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = df1.join(df1, ['PassengerId']).checkpoint()\n",
        "df.join(df1, ['PassengerId']).explain()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [PassengerId#0L, Name#1, Sex#2, Survived#3L, Name#421, Sex#422, Survived#423L, Name#439, Sex#440, Survived#441L]\n",
            "   +- SortMergeJoin [PassengerId#0L], [PassengerId#438L], Inner\n",
            "      :- Sort [PassengerId#0L ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(PassengerId#0L, 200), ENSURE_REQUIREMENTS, [id=#790]\n",
            "      :     +- Filter isnotnull(PassengerId#0L)\n",
            "      :        +- Scan ExistingRDD[PassengerId#0L,Name#1,Sex#2,Survived#3L,Name#421,Sex#422,Survived#423L]\n",
            "      +- Sort [PassengerId#438L ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(PassengerId#438L, 200), ENSURE_REQUIREMENTS, [id=#791]\n",
            "            +- Filter isnotnull(PassengerId#438L)\n",
            "               +- Scan ExistingRDD[PassengerId#438L,Name#439,Sex#440,Survived#441L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSSuarwGIm8x"
      },
      "source": [
        "**Partitions and repartition()**\n",
        "\n",
        "A common cause of performance problems is having too many partitions. \n",
        "\n",
        "To check the number of partitions, use `.rdd.getNumPartitions()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX9P4NXGIkL9",
        "outputId": "f4617822-ca17-4956-ccb5-4dda3548080c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.rdd.getNumPartitions()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHeGR3v9I-8T"
      },
      "source": [
        "This dataframe, despite having only 5 rows, has 2 partitions.\n",
        "\n",
        "This is too many, let's repartition to only 1 partition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt3l7kmDI-aX",
        "outputId": "53b8c9c6-6ce2-4c1e-b62f-b9210cb5b3a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1_repartitioned = df1.repartition(1)\n",
        "df1_repartitioned.rdd.getNumPartitions()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmYH_bst4KNs"
      },
      "source": [
        "Sources:\n",
        "https://changhsinlee.com/pyspark-dataframe-basics/\n",
        "\n",
        "More about unpacking: \n",
        "https://thispointer.com/python-how-to-unpack-list-tuple-or-dictionary-to-function-arguments-using/"
      ]
    }
  ]
}